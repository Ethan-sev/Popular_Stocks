{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price        Date      Close       High        Low       Open     Volume\n",
      "Ticker                  AAPL       AAPL       AAPL       AAPL       AAPL\n",
      "0      2020-03-05  71.085556  72.694512  70.719108  71.716516  187572800\n",
      "1      2020-03-06  70.141525  70.575923  68.248632  68.435492  226176800\n",
      "2      2020-03-09  64.593880  67.486610  63.824584  64.006593  286744800\n",
      "3      2020-03-10  69.246040  69.512989  65.370456  67.256077  285290000\n",
      "4      2020-03-11  66.841087  68.246201  65.974721  67.316744  255598800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Download Apple stock data from Yahoo Finance (last 5 years)\n",
    "ticker = \"AAPL\"\n",
    "data = yf.download(ticker, period=\"5y\")\n",
    "\n",
    "# Reset index to make 'Date' a column and ensure correct structure\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "# Save it to a CSV file\n",
    "data.to_csv(\"AAPL_cleaned_data.csv\", index=False)\n",
    "\n",
    "# Show the first few rows of the cleaned data to confirm\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepared Apple Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date       Close        High         Low        Open       Volume  \\\n",
      "200  2020-12-16  124.842369  125.389364  123.621393  124.451663   98208600.0   \n",
      "201  2020-12-17  125.711739  126.571311  125.067059  125.907092   94359800.0   \n",
      "202  2020-12-18  123.719093  126.102442  123.191631  125.965693  192541500.0   \n",
      "203  2020-12-21  125.252640  125.330784  120.583627  122.117173  121251600.0   \n",
      "204  2020-12-22  128.817902  131.289157  126.639669  128.554167  168904800.0   \n",
      "\n",
      "         SMA_10      SMA_50    SMA_200      EMA_10      EMA_50        RSI  \\\n",
      "200  120.946978  115.607111  94.827037  121.001448  115.924141  77.142749   \n",
      "201  121.509605  115.877059  95.100167  121.857864  116.307968  77.485184   \n",
      "202  121.940368  116.109299  95.368055  122.196269  116.598600  67.607518   \n",
      "203  122.377966  116.333205  95.671349  122.751973  116.937975  64.120907   \n",
      "204  123.110554  116.483518  95.969208  123.854869  117.403854  69.298180   \n",
      "\n",
      "         Target  \n",
      "200  125.711739  \n",
      "201  123.719093  \n",
      "202  125.252640  \n",
      "203  128.817902  \n",
      "204  127.919250  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the cleaned data (make sure to replace the file name with your actual CSV path)\n",
    "data = pd.read_csv(\"AAPL_cleaned_data.csv\")\n",
    "\n",
    "# Convert all columns to numeric where possible (this will coerce errors like 'AAPL' into NaN)\n",
    "data['Close'] = pd.to_numeric(data['Close'], errors='coerce')\n",
    "data['Open'] = pd.to_numeric(data['Open'], errors='coerce')\n",
    "data['High'] = pd.to_numeric(data['High'], errors='coerce')\n",
    "data['Low'] = pd.to_numeric(data['Low'], errors='coerce')\n",
    "data['Volume'] = pd.to_numeric(data['Volume'], errors='coerce')\n",
    "\n",
    "# Remove rows where any of the numeric columns have NaN values (caused by coercion)\n",
    "data.dropna(subset=['Close', 'Open', 'High', 'Low', 'Volume'], inplace=True)\n",
    "\n",
    "# 1. Add Moving Averages (SMA)\n",
    "data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "data['SMA_50'] = data['Close'].rolling(window=50).mean()\n",
    "data['SMA_200'] = data['Close'].rolling(window=200).mean()\n",
    "\n",
    "# 2. Add Exponential Moving Averages (EMA)\n",
    "data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "data['EMA_50'] = data['Close'].ewm(span=50, adjust=False).mean()\n",
    "\n",
    "# 3. Add Relative Strength Index (RSI)\n",
    "delta = data['Close'].diff()\n",
    "gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "\n",
    "rs = gain / loss\n",
    "data['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# 4. Add Future Price (Target/Label) - Here we're predicting the next day's closing price\n",
    "data['Target'] = data['Close'].shift(-1)\n",
    "\n",
    "# Drop rows with missing values due to rolling operations\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Save the prepared data for machine learning\n",
    "data.to_csv(\"AAPL_prepared_data.csv\", index=False)\n",
    "\n",
    "# Show the first few rows of the data\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 most popular tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Close for AAPL: arg must be a list, tuple, 1-d array, or Series\n",
      "Error processing Open for AAPL: arg must be a list, tuple, 1-d array, or Series\n",
      "Error processing High for AAPL: arg must be a list, tuple, 1-d array, or Series\n",
      "Error processing Low for AAPL: arg must be a list, tuple, 1-d array, or Series\n",
      "Error processing Volume for AAPL: arg must be a list, tuple, 1-d array, or Series\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['Close', 'Open', 'High', 'Low', 'Volume']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9144\\3876392884.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Error processing {col} for {ticker}: {e}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# Drop rows with missing values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Close'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Open'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'High'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Low'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Volume'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# Add Moving Averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SMA_10'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Sezy\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6414\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6415\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6416\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6417\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6418\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6419\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6421\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['Close', 'Open', 'High', 'Low', 'Volume']"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# List of 100 popular S&P 500 stocks\n",
    "tickers = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\", \"META\", \"TSLA\", \"BRK-B\", \"V\", \"JNJ\",\n",
    "    \"UNH\", \"XOM\", \"JPM\", \"PG\", \"MA\", \"HD\", \"LLY\", \"CVX\", \"ABBV\", \"AVGO\", \"PFE\", \"COST\", \"PEP\", \"KO\",\n",
    "    \"MRK\", \"NFLX\", \"TMO\", \"WMT\", \"DIS\", \"AMD\", \"BAC\", \"CSCO\", \"ABT\", \"ACN\", \"DHR\", \"NKE\", \"LIN\",\n",
    "    \"INTC\", \"MCD\", \"TXN\", \"VZ\", \"HON\", \"CRM\", \"GS\", \"MS\", \"NEE\", \"UNP\", \"BMY\", \"SCHW\", \"RTX\", \"AMGN\",\n",
    "    \"LOW\", \"C\", \"LMT\", \"CVS\", \"DE\", \"CAT\", \"ADBE\", \"IBM\", \"PYPL\", \"INTU\", \"MDT\", \"SBUX\", \"QCOM\",\n",
    "    \"PLD\", \"T\", \"NOW\", \"SPGI\", \"ISRG\", \"VRTX\", \"BKNG\", \"BLK\", \"CHTR\", \"MO\", \"GILD\", \"TGT\", \"EL\",\n",
    "    \"SYK\", \"MDLZ\", \"ZTS\", \"DUK\", \"SO\", \"PGR\", \"HUM\", \"CI\", \"MMC\", \"FIS\", \"CB\", \"ADI\", \"ICE\", \"PNC\",\n",
    "    \"BDX\", \"CSX\", \"NSC\", \"ITW\", \"EQIX\", \"CME\", \"EW\", \"TRV\", \"SHW\", \"HCA\"\n",
    "]\n",
    "\n",
    "# List to store processed data\n",
    "all_data = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"Processing {ticker}...\")\n",
    "\n",
    "    # Download stock data\n",
    "    data = yf.download(ticker, period=\"5y\")\n",
    "\n",
    "    # Skip if no data\n",
    "    if data.empty:\n",
    "        print(f\"❌ No data for {ticker}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Reset index to keep 'Date' as a column\n",
    "    data.reset_index(inplace=True)\n",
    "\n",
    "    # Ensure columns are numeric\n",
    "    for col in ['Close', 'Open', 'High', 'Low', 'Volume']:\n",
    "        if col in data.columns:\n",
    "            try:\n",
    "                data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {col} for {ticker}: {e}\")\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    data.dropna(subset=['Close', 'Open', 'High', 'Low', 'Volume'], inplace=True)\n",
    "\n",
    "    # Add Moving Averages\n",
    "    data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "    data['SMA_50'] = data['Close'].rolling(window=50).mean()\n",
    "    data['SMA_200'] = data['Close'].rolling(window=200).mean()\n",
    "\n",
    "    # Add Exponential Moving Averages\n",
    "    data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    data['EMA_50'] = data['Close'].ewm(span=50, adjust=False).mean()\n",
    "\n",
    "    # Add Relative Strength Index (RSI)\n",
    "    delta = data['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    data['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # Add Future Price (Target)\n",
    "    data['Target'] = data['Close'].shift(-1)\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # Add ticker column\n",
    "    data['Ticker'] = ticker\n",
    "\n",
    "    # Store the processed data\n",
    "    all_data.append(data)\n",
    "\n",
    "# Combine all stock data into one CSV\n",
    "if all_data:\n",
    "    final_data = pd.concat(all_data, ignore_index=True)\n",
    "    final_data.to_csv(\"popular_stocks_prepared_data.csv\", index=False)\n",
    "    print(\"✅ Data saved to popular_stocks_prepared_data.csv\")\n",
    "else:\n",
    "    print(\"❌ No valid data found for any ticker.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
